{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce18f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI project\n",
    "print(\"Group Members: \\n 1. Rehan ul hasaan - 'L1F19BSCS0424' \\n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d1d774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data From File is: \n",
      "\n",
      "Paragraphs are the building blocks of papers. Many students define paragraphs in terms of length: a paragraph is a group of at least five sentences, a paragraph is half a page long, etc. In reality, though, the unity and coherence of ideas among sentences is what constitutes a paragraph. A paragraph is defined as “a group of sentences or a single sentence that forms a unit” (Lunsford and Connors 116). Length and appearance do not determine whether a section in a paper is a paragraph. For instance, in some styles of writing, particularly journalistic styles, a paragraph can be just one sentence long. Ultimately, a paragraph is a sentence or group of sentences that support one main idea. In this handout, we will refer to this as the “controlling idea,” because it controls what happens in the rest of the paragraph.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Data after removing stop Words and symbols: \n",
      "\n",
      "Paragraphs building blocks papers Many students define paragraphs terms length paragraph group least five sentences paragraph half page long etc In reality though unity coherence ideas among sentences constitutes paragraph A paragraph defined “a group sentences single sentence forms unit” Lunsford Connors  Length appearance determine whether section paper paragraph For instance styles writing particularly journalistic styles paragraph one sentence long Ultimately paragraph sentence group sentences support one main idea In handout refer “controlling idea” controls happens rest paragraph\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# library for stopwords\n",
    "import io \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#reading a file\n",
    "data = open('file.txt', 'r').read()\n",
    "print(\"Data From File is: \\n\")\n",
    "print(data)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# installing nltk dependency\n",
    "# %pip install nltk\n",
    "# %pip install nltk.corpus\n",
    "# downloading stopwords\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "#storing stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_data = []\n",
    "\n",
    "#splitting words\n",
    "words = data.split()\n",
    "#removing stop words\n",
    "for r in words: \n",
    "    if not r in stop_words:\n",
    "        filtered_data.append(r)\n",
    "#initializing symbols\n",
    "symbols = \"{}()[].,:;+-*/&|<>=~$1234567890\"\n",
    "result = []\n",
    "for r in filtered_data:\n",
    "    temp = \"\"\n",
    "    for c in r:\n",
    "        if c not in symbols:\n",
    "            temp+=c\n",
    "    result.append(temp)    \n",
    "            \n",
    "#printing filtered data\n",
    "s = \" \"\n",
    "print(\"Data after removing stop Words and symbols: \\n\")\n",
    "# joining the words and printing as a data\n",
    "print(s.join(result))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "#now we will apply k-mean clustering to the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d3ca6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#installing kmeans library\n",
    "# sudo pacman -S python-scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "vectorizer = CountVectorizer()\n",
    "#vectorizing the data\n",
    "X = vectorizer.fit_transform(result)\n",
    "#applying kmean\n",
    "kmeans = KMeans(n_clusters=2,init='k-means++', max_iter=600, n_init=10)\n",
    "#identifying clusters\n",
    "kmeans.fit(X)\n",
    "#predicted kmeans\n",
    "identified_clusters = kmeans.fit_predict(X)\n",
    "identified_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82c4e0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480aa9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0fcc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f94fbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed271a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
